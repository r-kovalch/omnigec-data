{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tempfile\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora = \"wiki\" # \"reddit\" # \"uber\"\n",
    "\n",
    "eval_df = pd.read_csv(f\"../../datasets/automatic_evaluation/mutliref.csv\")\n",
    "eval_df = eval_df.loc[:, [\n",
    "    \"feature\",\n",
    "    \"target\",\n",
    "    \"spivavtor_correction\",\n",
    "    \"pravopysnyk_correction\",\n",
    "    \"language_tool_correction\"\n",
    "]]\n",
    "reference_columns = [\n",
    "    \"spivavtor_correction\",\n",
    "    \"pravopysnyk_correction\",\n",
    "    \"language_tool_correction\",\n",
    "]\n",
    "eval_df.loc[eval_df.loc[:, \"corpora\"] == corpora]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_df = eval_df.dropna(subset=['text', 'correction', *reference_columns])\n",
    "\n",
    "if filtered_df.empty:\n",
    "    print(\"No valid rows for evaluation with multiple references.\")\n",
    "else:\n",
    "    # Preprocess each essay to force one-line formatting: replace newlines with a space.\n",
    "    sources = [s.replace(\"\\n\", \" \").strip() for s in filtered_df['text'].tolist()]\n",
    "    hypotheses = [h.replace(\"\\n\", \" \").strip() for h in filtered_df['correction'].tolist()]\n",
    "    refs1 = [r.replace(\"\\n\", \" \").strip() for r in filtered_df[reference_columns[0]].tolist()]\n",
    "    refs2 = [r.replace(\"\\n\", \" \").strip() for r in filtered_df[reference_columns[1]].tolist()]\n",
    "    refs3 = [r.replace(\"\\n\", \" \").strip() for r in filtered_df[reference_columns[2]].tolist()]\n",
    "\n",
    "    # Write the sources, hypotheses, and each reference set to separate temporary files.\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as src_file, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as hyp_file, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as ref_file1, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as ref_file2, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as ref_file3:\n",
    "\n",
    "         src_file.write('\\n'.join(sources) + '\\n')\n",
    "         hyp_file.write('\\n'.join(hypotheses) + '\\n')\n",
    "         ref_file1.write('\\n'.join(refs1) + '\\n')\n",
    "         ref_file2.write('\\n'.join(refs2) + '\\n')\n",
    "         ref_file3.write('\\n'.join(refs3) + '\\n')\n",
    "\n",
    "         src_file_path = src_file.name\n",
    "         hyp_file_path = hyp_file.name\n",
    "         ref_file1_path = ref_file1.name\n",
    "         ref_file2_path = ref_file2.name\n",
    "         ref_file3_path = ref_file3.name\n",
    "\n",
    "    # Build the GLEU command: pass all three reference files.\n",
    "    gleu_command = [\n",
    "        'gleu',\n",
    "        '-s', src_file_path,\n",
    "        '-r', ref_file1_path, ref_file2_path, ref_file3_path,\n",
    "        '-o', hyp_file_path,\n",
    "        '-d', '4',  # Maximum n-gram length.\n",
    "        '-f',       # Calculate sentence-level GLEU.\n",
    "        '-n', '4',  # Order of n-grams.\n",
    "        '-t', 'word'  # Tokenization type.\n",
    "    ]\n",
    "\n",
    "    print(f\"Running GLEU command: {' '.join(gleu_command)}\")\n",
    "    gleu_output = os.popen(' '.join(gleu_command)).read()\n",
    "    print(gleu_output)\n",
    "\n",
    "    if gleu_output != \"\":\n",
    "        gleu_split = gleu_output.split()\n",
    "        gleu_score = gleu_split[1] if len(gleu_split) > 1 else \"n/a\"\n",
    "    else:\n",
    "        gleu_score = \"n/a\"\n",
    "\n",
    "    # Clean up temporary files.\n",
    "    os.remove(src_file_path)\n",
    "    os.remove(hyp_file_path)\n",
    "    os.remove(ref_file1_path)\n",
    "    os.remove(ref_file2_path)\n",
    "    os.remove(ref_file3_path)\n",
    "\n",
    "    # Store and display the result.\n",
    "    results = {\n",
    "        'reference_columns': reference_columns,\n",
    "        'gleu_score': gleu_score,\n",
    "        'n_sentences': len(filtered_df)\n",
    "    }\n",
    "\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_df.to_csv(f\"../../datasets/automatic_evaluation/{corpora}_gleu_multi_ref.csv\", index=False)\n",
    "    display(results_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "filtered_df = eval_df.dropna(subset=['text', 'correction', *reference_columns])\n",
    "language = filtered_df.language.unique()[0]\n",
    "language_to_lang_code_mapping = {\n",
    "    \"ukrainian\": \"uk\",\n",
    "}\n",
    "lang_code = language_to_lang_code_mapping[language]\n",
    "\n",
    "# If filtered_df is empty, you won't get any scores\n",
    "if filtered_df.empty:\n",
    "    print(\"No valid rows for multi-reference ERRANT scoring.\")\n",
    "    errant_results_df = pd.DataFrame(columns=[\"n_sentences\", \"precision\", \"recall\", \"f0.5\"])\n",
    "    errant_results_df.to_csv(f\"../../datasets/automatic_evaluation/{corpora}_errant_multi_ref.csv\", index=False)\n",
    "else:\n",
    "    # ------------------------------------------------------\n",
    "    # Convert multiline to single-line text for each column\n",
    "    # ------------------------------------------------------\n",
    "    originals = [t.replace(\"\\n\", \" \").strip() for t in filtered_df['text'].tolist()]\n",
    "    predictions = [p.replace(\"\\n\", \" \").strip() for p in filtered_df['correction'].tolist()]\n",
    "    refs1 = [r.replace(\"\\n\", \" \").strip() for r in filtered_df[reference_columns[0]].tolist()]\n",
    "    refs2 = [r.replace(\"\\n\", \" \").strip() for r in filtered_df[reference_columns[1]].tolist()]\n",
    "    refs3 = [r.replace(\"\\n\", \" \").strip() for r in filtered_df[reference_columns[2]].tolist()]\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Write these to temporary .tmp files for original/prediction/refs\n",
    "    # ----------------------------------------------------------------\n",
    "    with tempfile.NamedTemporaryFile(delete=False, mode='w') as orig_f, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as pred_f, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as ref1_f, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as ref2_f, \\\n",
    "         tempfile.NamedTemporaryFile(delete=False, mode='w') as ref3_f:\n",
    "\n",
    "        orig_f.write(\"\\n\".join(originals) + \"\\n\")\n",
    "        pred_f.write(\"\\n\".join(predictions) + \"\\n\")\n",
    "        ref1_f.write(\"\\n\".join(refs1) + \"\\n\")\n",
    "        ref2_f.write(\"\\n\".join(refs2) + \"\\n\")\n",
    "        ref3_f.write(\"\\n\".join(refs3) + \"\\n\")\n",
    "\n",
    "        orig_f_path = orig_f.name\n",
    "        pred_f_path = pred_f.name\n",
    "        ref1_f_path = ref1_f.name\n",
    "        ref2_f_path = ref2_f.name\n",
    "        ref3_f_path = ref3_f.name\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 1) Build an M2 for the references (multi-ref).\n",
    "    #    \"errant_parallel -orig <orig> -cor <ref1> <ref2> <ref3> -out <ref_m2> -lang en\"\n",
    "    # ----------------------------------------------------------------\n",
    "    ref_m2 = ref1_f_path.replace(\".tmp\", \"\") + \"_ref.m2\"  # or use a temp file\n",
    "    errant_parallel_refs_cmd = (\n",
    "        f\"errant_parallel -orig {orig_f_path} \"\n",
    "        f\"-cor {ref1_f_path} {ref2_f_path} {ref3_f_path} \"\n",
    "        f\"-out {ref_m2} -lang {lang_code}\"\n",
    "    )\n",
    "    print(\"Building reference M2:\\n\", errant_parallel_refs_cmd)\n",
    "    os.system(errant_parallel_refs_cmd)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 2) Build an M2 for the prediction\n",
    "    #    \"errant_parallel -orig <orig> -cor <prediction> -out <hyp_m2> -lang en\"\n",
    "    # ----------------------------------------------------------------\n",
    "    hyp_m2 = pred_f_path.replace(\".tmp\", \"\") + \"_pred.m2\"\n",
    "    errant_parallel_pred_cmd = (\n",
    "        f\"errant_parallel -orig {orig_f_path} \"\n",
    "        f\"-cor {pred_f_path} \"\n",
    "        f\"-out {hyp_m2} -lang {lang_code}\"\n",
    "    )\n",
    "    print(\"Building prediction M2:\\n\", errant_parallel_pred_cmd)\n",
    "    os.system(errant_parallel_pred_cmd)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 3) Compare the two M2 files with errant_compare\n",
    "    #    \"errant_compare -hyp <hyp_m2> -ref <ref_m2>\"\n",
    "    # ----------------------------------------------------------------\n",
    "    errant_compare_cmd = f\"errant_compare -hyp {hyp_m2} -ref {ref_m2}\"\n",
    "    print(\"Comparing M2 files:\\n\", errant_compare_cmd)\n",
    "    errant_output = os.popen(errant_compare_cmd).read()\n",
    "    print(errant_output)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Parse the precision, recall, and F0.5 from ERRANTâ€™s output\n",
    "    # Example block:\n",
    "    # =========== Span-Based Correction ============\n",
    "    # TP      FP      FN      Prec    Rec     F0.5\n",
    "    # 12      4       6       0.75    0.6667  0.7317\n",
    "    # ==============================================\n",
    "    # ----------------------------------------------------------------\n",
    "    prf_pattern = re.compile(r\"(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\\s+(\\d+\\.\\d+)\")\n",
    "    match = prf_pattern.search(errant_output)\n",
    "    if match:\n",
    "        precision_str, recall_str, f05_str = match.groups()\n",
    "    else:\n",
    "        precision_str, recall_str, f05_str = \"0\", \"0\", \"0\"\n",
    "\n",
    "    # Convert to numeric and store\n",
    "    precision = float(precision_str) * 100\n",
    "    recall = float(recall_str) * 100\n",
    "    f05 = float(f05_str) * 100\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Build final DataFrame with results, write to CSV\n",
    "    # ----------------------------------------------------------------\n",
    "    results_dict = {\n",
    "        \"n_sentences\": len(filtered_df),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f0.5\": f05\n",
    "    }\n",
    "    errant_results_df = pd.DataFrame([results_dict])\n",
    "    errant_results_df.to_csv(f\"../../datasets/automatic_evaluation/{corpora}_errant_multi_ref.csv\", index=False)\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # Cleanup: remove the .tmp and .m2 files if desired\n",
    "    # ----------------------------------------------------------------\n",
    "    os.remove(orig_f_path)\n",
    "    os.remove(pred_f_path)\n",
    "    os.remove(ref1_f_path)\n",
    "    os.remove(ref2_f_path)\n",
    "    os.remove(ref3_f_path)\n",
    "    if os.path.exists(ref_m2):\n",
    "        os.remove(ref_m2)\n",
    "    if os.path.exists(hyp_m2):\n",
    "        os.remove(hyp_m2)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
