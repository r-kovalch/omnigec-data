{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install regex pandas syntok\n",
    "\n",
    "!git clone https://github.com/cainesap/errant\n",
    "!cd errant\n",
    "!pip install -e .\n",
    "!cd ../\n",
    "\n",
    "!git clone https://github.com/cainesap/spacy_conll\n",
    "!cd spacy_conll\n",
    "!pip install -e .\n",
    "!cd ../\n",
    "\n",
    "!pip install spacy-udpipe\n",
    "!pip install evaluate\n",
    "!mkdir spacy_udpipe_models\n",
    "!pip install language-tool-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd gleu && pip install -e ."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "from tqdm import tqdm\n",
    "import language_tool_python\n",
    "\n",
    "from src.prompts.automatic_evaluation.spivavtor import SpivavtorGECPrompt, spivavtor_gec_verbalizers\n",
    "import random\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tqdm.pandas\n",
    "\n",
    "evaluation_df = pd.read_csv(\"../../datasets/annotations/anot_1500.csv\")\n",
    "evaluation_df.loc[:, \"language\"] = \"ukrainian\"\n",
    "evaluation_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"grammarly/spivavtor-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"grammarly/spivavtor-large\").to(device=\"mps\")\n",
    "\n",
    "def spivavtor_gec(input_text: str) -> str:\n",
    "    input = SpivavtorGECPrompt().prompt_template.format(\n",
    "        original_text=input_text,\n",
    "        verbalizer=random.choice(spivavtor_gec_verbalizers)\n",
    "    )\n",
    "    inputs = tokenizer.encode(input, return_tensors=\"pt\").to(device=\"mps\")\n",
    "    output = model.generate(inputs, max_length=256)\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    return output_text\n",
    "\n",
    "evaluation_df.loc[:, \"spivavtor_correction\"] = evaluation_df.loc[:, \"text\"].progress_apply(\n",
    "    lambda x: spivavtor_gec(x)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_checkpoint = \"Pravopysnyk/best-unlp\"\n",
    "translator = pipeline(\"translation\", src_lang=\"uk_UA\", tgt_lang=\"uk_UA\", model=model_checkpoint, device=\"mps\")\n",
    "\n",
    "ukrainian_mask = (evaluation_df.loc[:, \"language\"] == \"ukrainian\")\n",
    "evaluation_df.loc[ukrainian_mask, \"pravopysnyk_correction\"] = evaluation_df.loc[ukrainian_mask, \"text\"].progress_apply(\n",
    "    lambda x: translator(x, max_length=400)\n",
    ")\n",
    "evaluation_df.loc[ukrainian_mask, \"pravopysnyk_correction\"] = evaluation_df.loc[ukrainian_mask, \"pravopysnyk_correction\"].progress_apply(\n",
    "    lambda x: x[0]['translation_text']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "language_mapping = {\n",
    "    'ukrainian': 'uk-UA'\n",
    "}\n",
    "\n",
    "def correct_text(text, lang):\n",
    "    # Map the language to the corresponding LanguageTool code\n",
    "    lt_lang_code = language_mapping.get(lang)\n",
    "    if not lt_lang_code:\n",
    "        # If the language is not supported, return the original text\n",
    "        print(\"lang\", lang, \" not found\")\n",
    "\n",
    "        return text\n",
    "    # Initialize LanguageTool for the specified language\n",
    "    tool = language_tool_python.LanguageTool(lt_lang_code)\n",
    "    # Check and correct the text\n",
    "    matches = tool.check(text)\n",
    "    print(len(matches))\n",
    "    corrected_text = language_tool_python.utils.correct(text, matches)\n",
    "    # Close the LanguageTool instance\n",
    "    tool.close()\n",
    "    return corrected_text\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "evaluation_df.loc[:, 'language_tool_correction'] = evaluation_df.progress_apply(\n",
    "    lambda row: correct_text(row['text'], row['language']),\n",
    "    axis=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluation_df.to_csv(\"../../datasets/automatic_evaluation/multiref.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
